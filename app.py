import streamlit as st
import pandas as pd
from googleapiclient.discovery import build
import google.generativeai as genai
import time
import random
import json
import altair as alt
import streamlit.components.v1 as components
import io
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from collections import OrderedDict

# =================================================
# 0. å›ºå®šè¨­å®š
# =================================================
SEARCH_ENGINE_ID = "23e43fb5e029f4b50"  # CX å¯«æ­»ï¼ˆéæ©Ÿå¯†ï¼‰

# =================================================
# 1. Page Config
# =================================================
st.set_page_config(
    page_title="Google SERP æˆ°ç•¥é›·é” v3.3 (Parallel)",
    page_icon="ğŸ¯",
    layout="wide"
)

st.title("ğŸ¯ Google SERP æˆ°ç•¥é›·é” v3.3")
st.markdown("""
### Private SEO Weapon: Battlefield Strategy Reader  
**SERP æˆ°å ´åˆ¤è®€ â†’ ç­–ç•¥è¼¸å‡ºï¼ˆExcelï¼‰ï½œå¹³è¡Œè™•ç†ç‰ˆ**
""")

# =================================================
# 2. Sidebar
# =================================================
with st.sidebar:
    st.header("ğŸ”‘ API è¨­å®š")
    GOOGLE_API_KEY = st.text_input("Google API Key", type="password")
    GEMINI_API_KEY = st.text_input("Gemini API Key", type="password")

    st.divider()
    st.header("ğŸ§  æ¨¡å‹")
    MODEL_NAME = st.selectbox(
        "åˆ†ææ¨¡å‹",
        ["gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash"],
        index=0
    )

    st.divider()
    st.header("ğŸŒ æœå°‹è¨­å®š")
    TARGET_GL = st.text_input("åœ°å€ (gl)", value="tw")
    TARGET_HL = st.text_input("èªè¨€ (hl)", value="zh-TW")
    MAX_PAGES = st.slider("æŠ“å–é æ•¸", 1, 3, 2)

    st.divider()
    st.header("âš¡ æ•ˆèƒ½è¨­å®š")
    MAX_CONCURRENT_SERP = st.slider(
        "SERP åŒæ™‚è«‹æ±‚æ•¸", 
        min_value=1, 
        max_value=5, 
        value=3,
        help="Google CSE API çš„ä¸¦ç™¼ä¸Šé™"
    )
    MAX_CONCURRENT_GEMINI = st.slider(
        "Gemini åŒæ™‚è«‹æ±‚æ•¸", 
        min_value=1, 
        max_value=3, 
        value=2,
        help="å»ºè­°ä¿å®ˆè¨­å®šï¼Œé¿å…æ’ RPM é™åˆ¶"
    )
    GEMINI_MIN_INTERVAL = st.slider(
        "Gemini è«‹æ±‚é–“éš”ï¼ˆç§’ï¼‰",
        min_value=0.5,
        max_value=3.0,
        value=1.0,
        step=0.5,
        help="æ¯æ¬¡ Gemini å‘¼å«çš„æœ€å°é–“éš”"
    )

# =================================================
# 2.1 Google CSE é è¦½ï¼ˆä¸è€— Quotaï¼‰
# =================================================
with st.expander("ğŸ‘€ Google æœå°‹é è¦½ï¼ˆä¸è€— APIï¼‰"):
    components.html(
        f"""
        <script async src="https://cse.google.com/cse.js?cx={SEARCH_ENGINE_ID}"></script>
        <div class="gcse-search"></div>
        """,
        height=600,
        scrolling=True
    )

# =================================================
# 3. Rate Limited Executorï¼ˆæ ¸å¿ƒå¹³è¡Œæ§åˆ¶ï¼‰
# =================================================
class RateLimitedExecutor:
    """å¸¶ rate limit çš„å¹³è¡ŒåŸ·è¡Œå™¨ï¼Œé˜²æ­¢ API éè¼‰"""
    
    def __init__(self, max_concurrent_serp=3, max_concurrent_gemini=2, gemini_min_interval=1.0):
        self.serp_semaphore = threading.Semaphore(max_concurrent_serp)
        self.gemini_semaphore = threading.Semaphore(max_concurrent_gemini)
        self.gemini_last_call = 0
        self.gemini_min_interval = gemini_min_interval
        self.lock = threading.Lock()
        
        # çµ±è¨ˆç”¨
        self.stats = {
            "serp_calls": 0,
            "gemini_calls": 0,
            "gemini_retries": 0,
            "errors": []
        }
    
    def call_serp(self, func, *args, **kwargs):
        """åŸ·è¡Œ SERP API å‘¼å«ï¼Œå¸¶ä¸¦ç™¼æ§åˆ¶"""
        with self.serp_semaphore:
            try:
                result = func(*args, **kwargs)
                with self.lock:
                    self.stats["serp_calls"] += 1
                time.sleep(0.5)  # åŸºæœ¬é–“éš”é¿å…éå¿«
                return result
            except Exception as e:
                with self.lock:
                    self.stats["errors"].append(f"SERP: {str(e)}")
                raise
    
    def call_gemini(self, func, *args, **kwargs):
        """åŸ·è¡Œ Gemini API å‘¼å«ï¼Œå¸¶ä¸¦ç™¼æ§åˆ¶ + é€Ÿç‡é™åˆ¶ + é‡è©¦"""
        with self.gemini_semaphore:
            # ç¢ºä¿æœ€å°é–“éš”
            with self.lock:
                elapsed = time.time() - self.gemini_last_call
                if elapsed < self.gemini_min_interval:
                    time.sleep(self.gemini_min_interval - elapsed)
                self.gemini_last_call = time.time()
            
            # Exponential backoff retry
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    result = func(*args, **kwargs)
                    with self.lock:
                        self.stats["gemini_calls"] += 1
                    return result
                except Exception as e:
                    error_str = str(e).lower()
                    is_rate_limit = any(x in error_str for x in ["429", "quota", "rate", "limit"])
                    
                    if is_rate_limit and attempt < max_retries - 1:
                        wait_time = (2 ** attempt) + random.uniform(0.5, 1.5)
                        with self.lock:
                            self.stats["gemini_retries"] += 1
                        time.sleep(wait_time)
                    else:
                        with self.lock:
                            self.stats["errors"].append(f"Gemini: {str(e)}")
                        raise
            
            # æœ€å¾Œä¸€æ¬¡å˜—è©¦
            return func(*args, **kwargs)


# =================================================
# 4. Helper Functions
# =================================================
def detect_page_type(item):
    """åˆ¤æ–· SERP çµæœçš„é é¢é¡å‹"""
    link = (item.get("link") or "").lower()
    title = (item.get("title") or "").lower()

    if any(x in link for x in ["ptt.cc", "dcard", "reddit", "mobile01"]):
        return "UGC / Forum"
    if any(x in link for x in ["youtube.com", "instagram.com", "tiktok.com"]):
        return "Social / Video"
    if any(x in link for x in ["shopee", "momo", "pchome", "amazon", "/product/"]):
        return "E-commerce"
    if any(x in link for x in ["udn.com", "ltn.com", "ettoday", "/news/"]):
        return "Media"
    if "wiki" in link:
        return "Wiki"
    if any(x in title for x in ["åƒ¹æ ¼", "å„ªæƒ ", "æ¨è–¦"]):
        return "Commercial Content"
    return "General"


def get_serp_raw(api_key, keyword, gl, hl, pages):
    """
    æŠ“å– SERP è³‡æ–™ï¼ˆä¸ä½¿ç”¨ cacheï¼Œå› ç‚ºè¦åœ¨ thread ä¸­å‘¼å«ï¼‰
    """
    service = build("customsearch", "v1", developerKey=api_key)
    results = []

    for page in range(pages):
        start = page * 10 + 1
        res = service.cse().list(
            q=keyword,
            cx=SEARCH_ENGINE_ID,
            num=10,
            start=start,
            gl=gl,
            hl=hl
        ).execute()

        for i, item in enumerate(res.get("items", [])):
            desc = item.get("snippet", "") or ""
            if len(desc) > 200:
                desc = desc[:200] + "..."

            results.append({
                "Rank": start + i,
                "Type": detect_page_type(item),
                "Title": item.get("title"),
                "Description": desc,
                "DisplayLink": item.get("displayLink"),
                "URL": item.get("link")
            })

        # é é¢é–“çš„é–“éš”
        if page < pages - 1:
            time.sleep(0.8)

    return results


def repair_json(api_key, broken_text, error):
    """å˜—è©¦ä¿®å¾© Gemini å›å‚³çš„å£ JSON"""
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel("gemini-2.0-flash")

    prompt = f"""
Fix the JSON below and return ONLY valid JSON. No markdown, no explanation.

Error: {error}

Broken JSON:
{broken_text}
"""
    try:
        res = model.generate_content(prompt)
        text = res.text.strip()
        # æ¸…ç†å¯èƒ½çš„ markdown æ¨™è¨˜
        text = text.replace("```json", "").replace("```", "").strip()
        return json.loads(text)
    except Exception:
        return None


def analyze_strategy_raw(api_key, keyword, df, gl, model_name):
    """
    åŸ·è¡Œ Gemini ç­–ç•¥åˆ†æï¼ˆä¸ä½¿ç”¨ cacheï¼‰
    """
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(model_name)

    data = df[["Rank", "Type", "Title", "Description", "DisplayLink"]].to_string(index=False)

    prompt = f"""
ä½ æ˜¯ SEO ç­–ç•¥é¡§å•ã€‚
è«‹åˆ†æé—œéµå­—ã€Œ{keyword}ã€åœ¨ Googleï¼ˆ{gl}ï¼‰çš„ SERP æˆ°å ´ã€‚

è³‡æ–™ï¼š
{data}

è«‹åªç”¨ JSON å›å‚³ï¼Œä¸è¦ä»»ä½• markdown æ ¼å¼ã€ä¸è¦ ```json```ã€ä¸è¦ä»»ä½•å‰å¾Œèªªæ˜æ–‡å­—ï¼š
{{
  "User_Intent": "æè¿°ä½¿ç”¨è€…æœå°‹æ­¤é—œéµå­—çš„æ„åœ–",
  "Battlefield_Status": "ç›®å‰ SERP æˆ°å ´çš„ç«¶çˆ­ç‹€æ…‹åˆ†æ",
  "Opportunity_Gap": "ç™¼ç¾çš„æ©Ÿæœƒç¼ºå£",
  "Recommended_Page_Type": "å»ºè­°è£½ä½œçš„é é¢é¡å‹",
  "Winning_Angles": [
    {{ "angle": "åˆ‡è§’1", "target": "ç›®æ¨™å—çœ¾" }},
    {{ "angle": "åˆ‡è§’2", "target": "ç›®æ¨™å—çœ¾" }}
  ],
  "Killer_Titles": [
    {{ "title": "æ¨™é¡Œ1", "reason": "ç‚ºä½•æœ‰æ•ˆ" }},
    {{ "title": "æ¨™é¡Œ2", "reason": "ç‚ºä½•æœ‰æ•ˆ" }}
  ]
}}
"""

    try:
        res = model.generate_content(prompt)
        raw = res.text.strip()
        # å˜—è©¦æ¸…ç†ä¸¦è§£æ
        cleaned = raw.replace("```json", "").replace("```", "").strip()
        return json.loads(cleaned), raw
    except json.JSONDecodeError as e:
        # å˜—è©¦ä¿®å¾©
        fixed = repair_json(api_key, raw, str(e))
        if fixed:
            return fixed, raw
        return {"error": str(e), "raw_response": raw}, raw
    except Exception as e:
        return {"error": str(e)}, str(e)


def process_single_keyword(kw, executor, google_key, gemini_key, gl, hl, pages, model_name):
    """
    è™•ç†å–®ä¸€é—œéµå­—çš„å®Œæ•´æµç¨‹ï¼ˆSERP + åˆ†æï¼‰
    è¨­è¨ˆç‚ºå¯åœ¨ ThreadPool ä¸­åŸ·è¡Œ
    """
    result = {
        "keyword": kw,
        "serp_df": None,
        "serp_raw": None,
        "strategy": None,
        "raw_response": None,
        "error": None,
        "timing": {}
    }
    
    try:
        # Step 1: SERP æŠ“å–
        start_serp = time.time()
        serp_data = executor.call_serp(
            get_serp_raw, google_key, kw, gl, hl, pages
        )
        result["timing"]["serp"] = time.time() - start_serp
        result["serp_raw"] = serp_data
        result["serp_df"] = pd.DataFrame(serp_data)
        
        # Step 2: Gemini åˆ†æ
        start_gemini = time.time()
        strategy, raw = executor.call_gemini(
            analyze_strategy_raw, gemini_key, kw, result["serp_df"], gl, model_name
        )
        result["timing"]["gemini"] = time.time() - start_gemini
        result["strategy"] = strategy
        result["raw_response"] = raw
        
    except Exception as e:
        result["error"] = str(e)
    
    return result


# =================================================
# 5. Main App
# =================================================
keywords_input = st.text_area(
    "è¼¸å…¥é—œéµå­—ï¼ˆæ¯è¡Œä¸€å€‹ï¼Œè‡ªå‹•å»é‡ï¼‰",
    height=100,
    placeholder="ç©ºæ°£æ¸…æ·¨æ©Ÿ æ¨è–¦\nCRM ç³»çµ±æ¯”è¼ƒ\nè¾¦å…¬æ¤… ptt"
)

# é¡¯ç¤ºé ä¼°è³‡è¨Š
if keywords_input.strip():
    keywords_preview = list(dict.fromkeys([k.strip() for k in keywords_input.split("\n") if k.strip()]))
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("é—œéµå­—æ•¸", len(keywords_preview))
    with col2:
        st.metric("é ä¼° SERP å‘¼å«", len(keywords_preview) * MAX_PAGES)
    with col3:
        st.metric("é ä¼° Gemini å‘¼å«", len(keywords_preview))


if st.button("ğŸš€ å•Ÿå‹•æˆ°ç•¥åˆ†æ", type="primary"):
    if not (GOOGLE_API_KEY and GEMINI_API_KEY):
        st.error("è«‹è¼¸å…¥ Google API Key èˆ‡ Gemini API Key")
        st.stop()

    keywords = list(dict.fromkeys([k.strip() for k in keywords_input.split("\n") if k.strip()]))
    
    if not keywords:
        st.warning("è«‹è¼¸å…¥è‡³å°‘ä¸€å€‹é—œéµå­—")
        st.stop()

    # åˆå§‹åŒ–åŸ·è¡Œå™¨
    executor = RateLimitedExecutor(
        max_concurrent_serp=MAX_CONCURRENT_SERP,
        max_concurrent_gemini=MAX_CONCURRENT_GEMINI,
        gemini_min_interval=GEMINI_MIN_INTERVAL
    )
    
    # UI å…ƒç´ 
    st.divider()
    status_header = st.empty()
    status_header.info(f"âš¡ å¹³è¡Œè™•ç†ä¸­... SERPÃ—{MAX_CONCURRENT_SERP} / GeminiÃ—{MAX_CONCURRENT_GEMINI}")
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # ç”¨æ–¼æ”¶é›†çµæœï¼ˆä¿æŒé †åºï¼‰
    all_results = OrderedDict()
    completed_count = 0
    total_start_time = time.time()
    
    # =================================================
    # å¹³è¡ŒåŸ·è¡Œ
    # =================================================
    max_workers = max(MAX_CONCURRENT_SERP, MAX_CONCURRENT_GEMINI) + 1
    
    with ThreadPoolExecutor(max_workers=max_workers) as pool:
        # æäº¤æ‰€æœ‰ä»»å‹™
        future_to_kw = {
            pool.submit(
                process_single_keyword,
                kw, executor, GOOGLE_API_KEY, GEMINI_API_KEY,
                TARGET_GL, TARGET_HL, MAX_PAGES, MODEL_NAME
            ): kw for kw in keywords
        }
        
        # æ”¶é›†å®Œæˆçš„çµæœ
        for future in as_completed(future_to_kw):
            kw = future_to_kw[future]
            try:
                result = future.result()
            except Exception as e:
                result = {
                    "keyword": kw,
                    "error": str(e),
                    "serp_df": None,
                    "strategy": None
                }
            
            all_results[kw] = result
            completed_count += 1
            
            # æ›´æ–°é€²åº¦
            progress_bar.progress(completed_count / len(keywords))
            status_text.text(f"âœ… å®Œæˆï¼š{kw} ({completed_count}/{len(keywords)})")
    
    total_time = time.time() - total_start_time
    
    # æ¸…ç†é€²åº¦é¡¯ç¤º
    status_header.success(f"âœ… å…¨éƒ¨å®Œæˆï¼ç¸½è€—æ™‚ {total_time:.1f} ç§’")
    status_text.empty()
    
    # =================================================
    # é¡¯ç¤ºçµ±è¨ˆ
    # =================================================
    with st.expander("ğŸ“Š åŸ·è¡Œçµ±è¨ˆ", expanded=False):
        stat_cols = st.columns(4)
        with stat_cols[0]:
            st.metric("SERP å‘¼å«æ¬¡æ•¸", executor.stats["serp_calls"])
        with stat_cols[1]:
            st.metric("Gemini å‘¼å«æ¬¡æ•¸", executor.stats["gemini_calls"])
        with stat_cols[2]:
            st.metric("Gemini é‡è©¦æ¬¡æ•¸", executor.stats["gemini_retries"])
        with stat_cols[3]:
            st.metric("ç¸½è€—æ™‚", f"{total_time:.1f}s")
        
        if executor.stats["errors"]:
            st.warning(f"ç™¼ç”Ÿ {len(executor.stats['errors'])} å€‹éŒ¯èª¤")
            for err in executor.stats["errors"]:
                st.text(err)
    
    st.divider()
    
    # =================================================
    # æŒ‰åŸå§‹é †åºé¡¯ç¤ºçµæœ
    # =================================================
    reports = []
    serp_all_rows = []  # æ”¶é›†æ‰€æœ‰ SERP è³‡æ–™
    
    for kw in keywords:
        r = all_results.get(kw)
        if not r:
            continue
        
        st.subheader(f"ğŸ” {kw}")
        
        # é¡¯ç¤ºè™•ç†æ™‚é–“
        if r.get("timing"):
            timing = r["timing"]
            st.caption(f"â±ï¸ SERP: {timing.get('serp', 0):.1f}s ï½œ Gemini: {timing.get('gemini', 0):.1f}s")
        
        # éŒ¯èª¤è™•ç†
        if r.get("error"):
            st.error(f"âŒ è™•ç†å¤±æ•—ï¼š{r['error']}")
            st.divider()
            continue
        
        df = r.get("serp_df")
        strategy = r.get("strategy")
        
        # æ”¶é›† SERP åŸå§‹è³‡æ–™ï¼ˆåŠ å…¥é—œéµå­—æ¬„ä½ï¼‰
        if df is not None and not df.empty:
            serp_copy = df.copy()
            serp_copy.insert(0, "Keyword", kw)
            serp_all_rows.append(serp_copy)
        
        # æˆ°å ´åˆ†å¸ƒ
        with st.expander("ğŸ“Š æˆ°å ´åˆ†å¸ƒ", expanded=True):
            col1, col2 = st.columns([2, 1])
            with col1:
                if df is not None:
                    st.dataframe(
                        df[["Rank", "Type", "Title", "DisplayLink"]], 
                        use_container_width=True, 
                        height=220
                    )
            with col2:
                if df is not None and not df.empty:
                    type_counts = df["Type"].value_counts().reset_index()
                    type_counts.columns = ["Type", "Count"]
                    chart = alt.Chart(type_counts).mark_arc(innerRadius=50).encode(
                        theta="Count",
                        color="Type",
                        tooltip=["Type", "Count"]
                    )
                    st.altair_chart(chart, use_container_width=True)
        
        # ç­–ç•¥çµè«–
        if strategy and "error" not in strategy:
            st.markdown("### ğŸ§  ç­–ç•¥çµè«–")
            
            col_a, col_b = st.columns(2)
            with col_a:
                st.info(f"**ä½¿ç”¨è€…æ„åœ–**\n{strategy.get('User_Intent', 'N/A')}")
                st.success(f"**æ©Ÿæœƒç¼ºå£**\n{strategy.get('Opportunity_Gap', 'N/A')}")
            with col_b:
                st.warning(f"**æˆ°å ´ç‹€æ…‹**\n{strategy.get('Battlefield_Status', 'N/A')}")
                st.info(f"**å»ºè­°é å‹**\n{strategy.get('Recommended_Page_Type', 'N/A')}")

            st.markdown("**è‡´å‹åˆ‡è§’**")
            for a in strategy.get("Winning_Angles", []):
                st.markdown(f"- **{a.get('angle', '')}**ï¼ˆ{a.get('target', '')}ï¼‰")

            st.markdown("**å¿…å‹æ¨™é¡Œ**")
            for t in strategy.get("Killer_Titles", []):
                st.markdown(f"- {t.get('title', '')}ï½œ{t.get('reason', '')}")

            # åŠ å…¥å ±å‘Š
            strategy["Keyword"] = kw
            reports.append(strategy)
        
        elif strategy and "error" in strategy:
            st.error("âŒ ç­–ç•¥è§£æå¤±æ•—")
            with st.expander("æŸ¥çœ‹åŸå§‹å›æ‡‰"):
                st.code(r.get("raw_response", "N/A"))
        
        st.divider()

    # =================================================
    # 6. Excel è¼¸å‡ºï¼ˆé›™å·¥ä½œè¡¨ç‰ˆï¼‰
    # =================================================
    if reports:
        st.subheader("ğŸ“¥ ä¸‹è¼‰å ±å‘Š")
        
        # ç­–ç•¥å·¥ä½œè¡¨
        strategy_rows = []
        for r in reports:
            strategy_rows.append({
                "Keyword": r.get("Keyword", ""),
                "User_Intent": r.get("User_Intent", ""),
                "Battlefield_Status": r.get("Battlefield_Status", ""),
                "Opportunity_Gap": r.get("Opportunity_Gap", ""),
                "Recommended_Page_Type": r.get("Recommended_Page_Type", ""),
                "Winning_Angles": "\n".join(
                    [f"- {a.get('angle', '')}ï¼ˆ{a.get('target', '')}ï¼‰"
                     for a in r.get("Winning_Angles", [])]
                ),
                "Killer_Titles": "\n".join(
                    [f"- {t.get('title', '')}ï½œ{t.get('reason', '')}"
                     for t in r.get("Killer_Titles", [])]
                ),
                "Raw_JSON": json.dumps(r, ensure_ascii=False)
            })

        df_strategy = pd.DataFrame(strategy_rows)
        
        # SERP åŸå§‹è³‡æ–™å·¥ä½œè¡¨
        df_serp_all = pd.concat(serp_all_rows, ignore_index=True) if serp_all_rows else pd.DataFrame()

        # å¯«å…¥ Excel
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
            df_strategy.to_excel(writer, sheet_name="Strategy", index=False)
            
            if not df_serp_all.empty:
                df_serp_all.to_excel(writer, sheet_name="SERP_Raw", index=False)
            
            # èª¿æ•´æ¬„å¯¬
            workbook = writer.book
            for sheet_name in writer.sheets:
                worksheet = writer.sheets[sheet_name]
                worksheet.set_column('A:A', 20)
                worksheet.set_column('B:H', 40)

        col_dl1, col_dl2 = st.columns(2)
        with col_dl1:
            st.download_button(
                label="ğŸ“Š ä¸‹è¼‰å®Œæ•´ Excel å ±å‘Š",
                data=buffer.getvalue(),
                file_name=f"seo_strategy_{int(time.time())}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        with col_dl2:
            # JSON å‚™ä»½
            json_data = json.dumps(reports, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ“„ ä¸‹è¼‰ JSON å‚™ä»½",
                data=json_data,
                file_name=f"seo_strategy_{int(time.time())}.json",
                mime="application/json"
            )
